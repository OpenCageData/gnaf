# gnaf

Seeing what we can do with the [G-NAF data set](http://www.data.gov.au/dataset/geocoded-national-address-file-g-naf).

## Install Tools

To run the code install:
- a JRE e.g. from openjdk-7 or 8;
- the build tool [sbt](http://www.scala-sbt.org/).

To develop [Scala](http://scala-lang.org/) web services install:
- the above items (you may prefer to install the full JDK instead of just the JRE but I think the JRE is sufficient);
- the [Scala IDE](http://scala-ide.org/download/current.html).

Run `sbt update-classifiers` to download dependencies.

## Create Database

The scripts described here automate the procedure described in the [getting started guide](https://www.psma.com.au/sites/default/files/g-naf_-_getting_started_guide.pdf).

### Download data, Unpack & Generate SQL
Running:

	src/main/script/createGnafDb.sh

- downloads the G-NAF zip file to `data/` (if not found);
- unzips to `data/unzipped/` (if not found); and
- writes SQL to create the H2 database to `data/createGnafDb.sql` (`createGnafDb.sh` may require adaptation for other databases).

### Start Database Engine & SQL Client
The H2 database engine is started with:

	java -jar ~/.ivy2/cache/com.h2database/h2/jars/h2-1.4.191.jar

(the H2 jar file was put here by `sbt update-classifiers`, alternatively download the jar from the H2 web site and run it as above).
This should open the SQL client at http://127.0.1.1:8082/login.jsp in a web browser.

The database engine is stopped with `Ctrl-C` (but not yet as it's needed for the next step).

### Run SQL
In the SQL client, enter JDBC URL: `jdbc:h2:file:~/sw/gnaf/data/gnaf` (leaving the User name and Password fields blank) and click `Connect` to create an empty database at this location. This is a single file, zero-admin database. It can me moved/renamed simply by moving/renaming the `gnaf.mv.db` file.

Run the SQL commands either by:
- entering: `RUNSCRIPT FROM '~/sw/gnaf/data/createGnafDb.sql'` into the SQL input area (this method displays no indication of progress); or
- pasting the content of this file into the SQL input area (this method displays what is going on).

On a macbook-pro (with SSD) it takes 26 min to load the data and another 53 min to create the indexes. 

## Generate Slick bindings
[Slick](http://slick.typesafe.com/) provides "Functional Relational Mapping for Scala". To generate Slick mappings for the database (first disconnect any other clients):

    mkdir -p generated
    sbt
    > console
    slick.codegen.SourceCodeGenerator.main(
        Array("slick.driver.H2Driver", "org.h2.Driver", "jdbc:h2:file:~/sw/gnaf/gnaf", "generated", "au.com.data61.gnaf.db")
    )

This generates code in the `generated/au/com/data61/db` directory.
At this stage its not clear whether the mapping will:
1. need hand tweaks (i.e. once off generation then its part of the source code); or
2. not need hand tweaks and should be generated by the build and is not part of our source code (better if schema changes much/often).

For now we'll opt for 1 and move this into `src/main/scala`

## Example Queries
Find me (fast):

    SELECT SL.*, AD.*
    FROM
        STREET_LOCALITY SL
        LEFT JOIN ADDRESS_DETAIL AD ON AD.STREET_LOCALITY_PID = SL.STREET_LOCALITY_PID  
    WHERE SL.STREET_NAME = 'TYTHERLEIGH'
        AND AD.NUMBER_FIRST = 14

This is slow (45892 ms):

    SELECT * FROM ADDRESS_VIEW 
    WHERE STREET_NAME = 'TYTHERLEIGH'
    AND NUMBER_FIRST = 14

but at least this is fast:

    SELECT * FROM ADDRESS_VIEW 
    WHERE ADDRESS_DETAIL_PID = 'GAACT714928273'


## To Do
Build a webapp using the scala spray async framework
Look at slick async usage (and later how to do lucene async)

We have:
- PRIMARY_SECONDARY join table with PRIMARY_PID & SECONDARY_PID both referring to ADDRESS_DETAIL
- STREET_LOCALITY_ALIAS for alternative street names
- LOCALITY_ALIAS for alternative suburb names
- ADDRESS_ALIAS join table with PRINCIPAL_PID & ALIAS_PID both referring to ADDRESS_ALIAS
- ADDRESS_DETAIL.address_site_pid -> ADDRESS_SITE.ADDRESS_SITE_NAME = 'WANNIASSA HILLS PRIMARY SCH' etc. with ADDRESS_TYPE -> ADDRESS_TYPE_AUT: R -> RURAL, UR -> URBAN etc.
- ADDRESS_DETAIL.flat_type_code -> FLAT_TYPE_AUT CODE (Abbreviation) and NAME (full name) = DESCRIPTION

Lucene:
- Store short and long street type and state names and locality names and aliases as multiple values in the same field



Use it to (or just db queries) to explore the data to understand usage:
- house/unit number prefixes/suffixes first/last (I think for 3-5 lonsdale st)
- street types (abbreviations in STREET_TYPE_AUT)
- decide Lucene fields for data (need separate fields for everything to avoid spurious hits)
- do we need some sort of fuzzy fields (e.g. metaphone; look at what solr provides; lucene has fuzzy/edit distance)
- decide how to query: step 1) search all lucene fields for each query term; step 2) attempt some segmentation and search each lucene field for a subset of the query terms
